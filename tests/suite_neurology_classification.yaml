# DEL7.2: Technical Test Specification (Benchmark Suite)
# Neurology FM Evaluation - Focus: Robustness & Representation Quality

suite_id: "SUITE-NEURO-CLASS-001"
name: "Neurology fMRI Classification Benchmark Suite"
benchmark_id: "BM-FMRI-GRANULAR"

description: |
  Benchmark suite for evaluating fMRI foundation models on classification tasks.
  Focus: representation quality, robustness, and generalization.
  
  NOTE: This suite uses toy/synthetic data for testing. For full benchmarking,
  users should provide their own institutional data (UK Biobank, HCP, etc.).

# Execution Environment
runner: "python -m fmbench run"
environment:
  python: ">=3.9"
  gpu_required: false  # Can run on CPU for toy data

# Input Configuration
inputs:
  dataset:
    key: "dataset_id"
    default: "DS-TOY-FMRI-CLASS"  # Toy fMRI data included in repo
  model:
    key: "model_id"

# Evaluation Protocol
protocol:
  cross_validation:
    folds: 5
    strategy: "StratifiedKFold"
  
  metrics:
    - name: "AUROC"
      func: "sklearn.metrics.roc_auc_score"
    - name: "Accuracy"
      func: "sklearn.metrics.accuracy_score"
    - name: "F1-Score"
      func: "sklearn.metrics.f1_score"
  
  robustness_probes:
    - "dropout"
    - "noise"
    - "line_noise"
    - "permutation"
    - "shift"

# Output Specification
outputs:
  report_template: "templates/neuro_report.md"
  artifacts:
    - "eval.yaml"
    - "report.md"

# Usage
usage: |
  python -m fmbench run --suite SUITE-NEURO-CLASS-001 \
    --model configs/model_brainlm.yaml \
    --out results/brainlm_eval
