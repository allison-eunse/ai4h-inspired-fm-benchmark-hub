
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Benchmarking Hub for Genetics & Brain Foundation Models">
      
      
      
        <link rel="canonical" href="https://allison-eunse.github.io/ai4h-inspired-fm-benchmark-hub/leaderboards/">
      
      
        <link rel="prev" href="../how_it_works/">
      
      
        <link rel="next" href="../contributing/submission_guide/">
      
      
        
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Leaderboards - AI4H-Inspired FM Benchmarks</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="deep-purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#foundation-model-leaderboards" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="AI4H-Inspired FM Benchmarks" class="md-header__button md-logo" aria-label="AI4H-Inspired FM Benchmarks" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21.33 12.91c.09 1.55-.62 3.04-1.89 3.95l.77 1.49c.23.45.26.98.06 1.45-.19.47-.58.84-1.06 1l-.79.25a1.687 1.687 0 0 1-1.86-.55L14.44 18c-.89-.15-1.73-.53-2.44-1.1-.5.15-1 .23-1.5.23-.88 0-1.76-.27-2.5-.79-.53.16-1.07.23-1.62.22-.79.01-1.57-.15-2.3-.45a4.1 4.1 0 0 1-2.43-3.61c-.08-.72.04-1.45.35-2.11-.29-.75-.32-1.57-.07-2.33C2.3 7.11 3 6.32 3.87 5.82c.58-1.69 2.21-2.82 4-2.7 1.6-1.5 4.05-1.66 5.83-.37.42-.11.86-.17 1.3-.17 1.36-.03 2.65.57 3.5 1.64 2.04.53 3.5 2.35 3.58 4.47.05 1.11-.25 2.2-.86 3.13.07.36.11.72.11 1.09m-5-1.41c.57.07 1.02.5 1.02 1.07a1 1 0 0 1-1 1h-.63c-.32.9-.88 1.69-1.62 2.29.25.09.51.14.77.21 5.13-.07 4.53-3.2 4.53-3.25a2.59 2.59 0 0 0-2.69-2.49 1 1 0 0 1-1-1 1 1 0 0 1 1-1c1.23.03 2.41.49 3.33 1.3.05-.29.08-.59.08-.89-.06-1.24-.62-2.32-2.87-2.53-1.25-2.96-4.4-1.32-4.4-.4-.03.23.21.72.25.75a1 1 0 0 1 1 1c0 .55-.45 1-1 1-.53-.02-1.03-.22-1.43-.56-.48.31-1.03.5-1.6.56-.57.05-1.04-.35-1.07-.9a.97.97 0 0 1 .88-1.1c.16-.02.94-.14.94-.77 0-.66.25-1.29.68-1.79-.92-.25-1.91.08-2.91 1.29C6.75 5 6 5.25 5.45 7.2 4.5 7.67 4 8 3.78 9c1.08-.22 2.19-.13 3.22.25.5.19.78.75.59 1.29-.19.52-.77.78-1.29.59-.73-.32-1.55-.34-2.3-.06-.32.27-.32.83-.32 1.27 0 .74.37 1.43 1 1.83.53.27 1.12.41 1.71.4q-.225-.39-.39-.81a1.038 1.038 0 0 1 1.96-.68c.4 1.14 1.42 1.92 2.62 2.05 1.37-.07 2.59-.88 3.19-2.13.23-1.38 1.34-1.5 2.56-1.5m2 7.47-.62-1.3-.71.16 1 1.25zm-4.65-8.61a1 1 0 0 0-.91-1.03c-.71-.04-1.4.2-1.93.67-.57.58-.87 1.38-.84 2.19a1 1 0 0 0 1 1c.57 0 1-.45 1-1 0-.27.07-.54.23-.76.12-.1.27-.15.43-.15.55.03 1.02-.38 1.02-.92"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AI4H-Inspired FM Benchmarks
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Leaderboards
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="deep-purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="deep-purple"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/allison-eunse/ai4h-inspired-fm-benchmark-hub" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    ai4h-inspired-fm-benchmark-hub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../start_here/" class="md-tabs__link">
        
  
  
    
  
  Start Here

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../how_it_works/" class="md-tabs__link">
        
  
  
    
  
  How It Works

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
  
    
  
  Leaderboards

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../contributing/submission_guide/" class="md-tabs__link">
          
  
  
  Submit Results

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../integration/analysis_recipes/cca_permutation/" class="md-tabs__link">
          
  
  
  Protocols (Recipes)

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../data_sources/" class="md-tabs__link">
          
  
  
  Data Specs

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../models/" class="md-tabs__link">
          
  
  
  Models

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../design/ai4h_alignment/" class="md-tabs__link">
          
  
  
  Design

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../credits/" class="md-tabs__link">
        
  
  
    
  
  Credits

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="AI4H-Inspired FM Benchmarks" class="md-nav__button md-logo" aria-label="AI4H-Inspired FM Benchmarks" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21.33 12.91c.09 1.55-.62 3.04-1.89 3.95l.77 1.49c.23.45.26.98.06 1.45-.19.47-.58.84-1.06 1l-.79.25a1.687 1.687 0 0 1-1.86-.55L14.44 18c-.89-.15-1.73-.53-2.44-1.1-.5.15-1 .23-1.5.23-.88 0-1.76-.27-2.5-.79-.53.16-1.07.23-1.62.22-.79.01-1.57-.15-2.3-.45a4.1 4.1 0 0 1-2.43-3.61c-.08-.72.04-1.45.35-2.11-.29-.75-.32-1.57-.07-2.33C2.3 7.11 3 6.32 3.87 5.82c.58-1.69 2.21-2.82 4-2.7 1.6-1.5 4.05-1.66 5.83-.37.42-.11.86-.17 1.3-.17 1.36-.03 2.65.57 3.5 1.64 2.04.53 3.5 2.35 3.58 4.47.05 1.11-.25 2.2-.86 3.13.07.36.11.72.11 1.09m-5-1.41c.57.07 1.02.5 1.02 1.07a1 1 0 0 1-1 1h-.63c-.32.9-.88 1.69-1.62 2.29.25.09.51.14.77.21 5.13-.07 4.53-3.2 4.53-3.25a2.59 2.59 0 0 0-2.69-2.49 1 1 0 0 1-1-1 1 1 0 0 1 1-1c1.23.03 2.41.49 3.33 1.3.05-.29.08-.59.08-.89-.06-1.24-.62-2.32-2.87-2.53-1.25-2.96-4.4-1.32-4.4-.4-.03.23.21.72.25.75a1 1 0 0 1 1 1c0 .55-.45 1-1 1-.53-.02-1.03-.22-1.43-.56-.48.31-1.03.5-1.6.56-.57.05-1.04-.35-1.07-.9a.97.97 0 0 1 .88-1.1c.16-.02.94-.14.94-.77 0-.66.25-1.29.68-1.79-.92-.25-1.91.08-2.91 1.29C6.75 5 6 5.25 5.45 7.2 4.5 7.67 4 8 3.78 9c1.08-.22 2.19-.13 3.22.25.5.19.78.75.59 1.29-.19.52-.77.78-1.29.59-.73-.32-1.55-.34-2.3-.06-.32.27-.32.83-.32 1.27 0 .74.37 1.43 1 1.83.53.27 1.12.41 1.71.4q-.225-.39-.39-.81a1.038 1.038 0 0 1 1.96-.68c.4 1.14 1.42 1.92 2.62 2.05 1.37-.07 2.59-.88 3.19-2.13.23-1.38 1.34-1.5 2.56-1.5m2 7.47-.62-1.3-.71.16 1 1.25zm-4.65-8.61a1 1 0 0 0-.91-1.03c-.71-.04-1.4.2-1.93.67-.57.58-.87 1.38-.84 2.19a1 1 0 0 0 1 1c.57 0 1-.45 1-1 0-.27.07-.54.23-.76.12-.1.27-.15.43-.15.55.03 1.02-.38 1.02-.92"/></svg>

    </a>
    AI4H-Inspired FM Benchmarks
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/allison-eunse/ai4h-inspired-fm-benchmark-hub" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    ai4h-inspired-fm-benchmark-hub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../start_here/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Start Here
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../how_it_works/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    How It Works
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Leaderboards
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Leaderboards
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#example-what-a-real-submission-looks-like" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example: what a real submission looks like
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jump-to" class="md-nav__link">
    <span class="md-ellipsis">
      
        ğŸ§­ Jump To
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#genomics" class="md-nav__link">
    <span class="md-ellipsis">
      
        ğŸ§¬ Genomics
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ§¬ Genomics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#classification" class="md-nav__link">
    <span class="md-ellipsis">
      
        ğŸ¯ Classification
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ¯ Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dna-promoter-classification" class="md-nav__link">
    <span class="md-ellipsis">
      
        DNA Promoter Classification
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cell-type-annotation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Cell Type Annotation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dna-enhancer-classification" class="md-nav__link">
    <span class="md-ellipsis">
      
        DNA Enhancer Classification
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        âœï¸ Generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="âœï¸ Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#clinical-report-generation-quality" class="md-nav__link">
    <span class="md-ellipsis">
      
        Clinical Report Generation Quality
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#brain-imaging-mrifmri" class="md-nav__link">
    <span class="md-ellipsis">
      
        ğŸ§  Brain Imaging (MRI/fMRI)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ§  Brain Imaging (MRI/fMRI)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#classification_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        ğŸ¯ Classification
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ¯ Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#toy-classification-benchmark" class="md-nav__link">
    <span class="md-ellipsis">
      
        Toy Classification Benchmark
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classificationreconstruction" class="md-nav__link">
    <span class="md-ellipsis">
      
        ğŸ“‹ Classification/Reconstruction
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ“‹ Classification/Reconstruction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fmri-foundation-model-benchmark-granular" class="md-nav__link">
    <span class="md-ellipsis">
      
        fMRI Foundation Model Benchmark (Granular)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reconstruction" class="md-nav__link">
    <span class="md-ellipsis">
      
        ğŸ”„ Reconstruction
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ”„ Reconstruction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#brain-time-series-modeling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Brain Time-Series Modeling
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#other-benchmarks" class="md-nav__link">
    <span class="md-ellipsis">
      
        ğŸ“‹ Other Benchmarks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ğŸ“‹ Other Benchmarks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#foundation-model-robustness-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Foundation Model Robustness Evaluation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#add-your-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        ğŸš€ Add Your Model
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Submit Results
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Submit Results
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../contributing/submission_guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Submission Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Protocols (Recipes)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Protocols (Recipes)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../integration/analysis_recipes/cca_permutation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    CCA & Permutation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../integration/analysis_recipes/prediction_baselines/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Prediction Baselines
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../integration/analysis_recipes/partial_correlations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Partial Correlations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Data Specs
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Data Specs
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data_sources/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Free Data Sources
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../integration/modality_features/fmri/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    fMRI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../integration/modality_features/smri/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    sMRI
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../integration/modality_features/genomics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Genomics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    Models
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Design
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    Design
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../design/ai4h_alignment/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AI4H Alignment
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../credits/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Credits
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="foundation-model-leaderboards">ğŸ† Foundation Model Leaderboards</h1>
<div class="admonition success">
<p class="admonition-title">Benchmark Hub Overview</p>
<p>ğŸ“Š <strong>8</strong> Benchmarks | ğŸ¤– <strong>12</strong> Models | ğŸ“ˆ <strong>35</strong> Evaluations</p>
</div>
<blockquote>
<p><strong>What is this?</strong> This page ranks AI models for healthcare applications. 
Higher-ranked models perform better on standardized tests.</p>
<p><strong>How to read it:</strong> Each table shows models from best (ğŸ¥‡) to developing (ğŸ“ˆ).
Click "How are scores calculated?" for details on what the numbers mean.</p>
</blockquote>
<h2 id="example-what-a-real-submission-looks-like">Example: what a real submission looks like</h2>
<p>This is a <strong>real, end-to-end</strong> run using the built-in baseline model. Your submission should look like this: a local run that produces <code>report.md</code> + <code>eval.yaml</code>.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model ID</th>
<th style="text-align: left;">Suite / Benchmark</th>
<th style="text-align: left;">Task</th>
<th style="text-align: right;"><abbr title="Area Under the Receiver Operating Characteristic curve">AUROC</abbr></th>
<th style="text-align: right;"><abbr title="Reverse area-under-curve for channel dropout robustness">dropout rAUC</abbr></th>
<th style="text-align: right;"><abbr title="Reverse area-under-curve for Gaussian noise robustness">noise rAUC</abbr></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><code>dummy_classifier</code></td>
<td style="text-align: left;"><code>SUITE-TOY-CLASS</code> / <code>BM-TOY-CLASS</code></td>
<td style="text-align: left;">Toy fMRI-like classification</td>
<td style="text-align: right;">0.5597</td>
<td style="text-align: right;">0.7760</td>
<td style="text-align: right;">0.7867</td>
</tr>
</tbody>
</table>
<p><strong>Artifacts:</strong> <a href="https://github.com/allison-eunse/ai4h-inspired-fm-benchmark-hub/blob/main/evals/SUITE-TOY-CLASS-dummy_classifier-20251127-071011.yaml">Example classification eval.yaml</a> Â· <a href="https://github.com/allison-eunse/ai4h-inspired-fm-benchmark-hub/blob/main/reports/SUITE-TOY-CLASS-dummy_classifier-20251127-071011.md">Example classification report.md</a> Â· <a href="https://github.com/allison-eunse/ai4h-inspired-fm-benchmark-hub/blob/main/evals/ROBUSTNESS-dummy_classifier-20251127-071004.yaml">Example robustness eval.yaml</a> Â· <a href="https://github.com/allison-eunse/ai4h-inspired-fm-benchmark-hub/blob/main/reports/ROBUSTNESS-dummy_classifier-20251127-071004.md">Example robustness report.md</a></p>
<hr />
<h2 id="jump-to">ğŸ§­ Jump To</h2>
<ul>
<li><a href="#genomics">ğŸ§¬ Genomics</a></li>
<li><a href="#brain-imaging-mrifmri">ğŸ§  Brain Imaging (MRI/fMRI)</a></li>
</ul>
<hr />
<h2 id="genomics">ğŸ§¬ Genomics</h2>
<h3 id="classification">ğŸ¯ Classification</h3>
<h4 id="dna-promoter-classification">DNA Promoter Classification</h4>
<p>*Benchmark for classifying DNA sequences as promoters or non-promoters.
Promoters are regulatory regions at transcription start sites (TSS).
This benchmark focuses on non-TATA promoters, which lack the canonical
TATA box and represent ~75% of human promoters.
*</p>
<div align="center">

<div class="highlight"><pre><span></span><code>                    ğŸ†                    

              ğŸ¥‡ HyenaDNA              
                 (0.872)                 
             â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—             
             â•‘               â•‘             
   ğŸ¥ˆ Caduceus   â•‘               â•‘   ğŸ¥‰  Evo 2     
      (0.859)      â•‘               â•‘      (0.859)      
  â•”â•â•â•â•â•â•â•â•â•â•â•â•               â•šâ•â•â•â•â•â•â•â•â•â•â•â•—  
  â•‘                                       â•‘  
â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•
</code></pre></div>

</div>

<p><strong>6 models ranked by <code>AUROC</code>:</strong></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Rank</th>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Score</th>
<th style="text-align: center;">Level</th>
<th style="text-align: left;">Details</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ¥‡</td>
<td style="text-align: left;"><strong>HyenaDNA</strong> ğŸ‘‘</td>
<td style="text-align: center;">0.8720</td>
<td style="text-align: center;">âœ… Good</td>
<td style="text-align: left;">DS-DNA-PROMOTER, 2025-12-18T21:03:12.030852</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ¥ˆ</td>
<td style="text-align: left;"><strong>Caduceus</strong></td>
<td style="text-align: center;">0.8594</td>
<td style="text-align: center;">âœ… Good</td>
<td style="text-align: left;">Human Non-TATA Promo, 2025-12-19T12:00:12.829913</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ¥‰</td>
<td style="text-align: left;"><strong>Evo 2</strong></td>
<td style="text-align: center;">0.8594</td>
<td style="text-align: center;">âœ… Good</td>
<td style="text-align: left;">Human Non-TATA Promo, 2025-12-19T12:00:13.671201</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ…</td>
<td style="text-align: left;">kmer_k6</td>
<td style="text-align: center;">0.8357</td>
<td style="text-align: center;">âœ… Good</td>
<td style="text-align: left;">Human Non-TATA Promo, 2025-12-18T18:44:10.847321</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ…</td>
<td style="text-align: left;">DNABERT-2</td>
<td style="text-align: center;">0.8357</td>
<td style="text-align: center;">âœ… Good</td>
<td style="text-align: left;">Human Non-TATA Promo, 2025-12-18T18:44:27.391206</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ–ï¸</td>
<td style="text-align: left;">HyenaDNA</td>
<td style="text-align: center;">0.8357</td>
<td style="text-align: center;">âœ… Good</td>
<td style="text-align: left;">Human Non-TATA Promo, 2025-12-18T18:44:19.651418</td>
</tr>
</tbody>
</table>
<div class="admonition tip">
<p class="admonition-title">Quick Comparison</p>
<p><strong>ğŸ¥‡ HyenaDNA</strong> leads with AUROC = <strong>0.8720</strong></p>
<ul>
<li>Gap to ğŸ¥ˆ Caduceus: +0.0126</li>
<li>Score spread (best to worst): 0.0363</li>
</ul>
</div>
<details>
<summary>ğŸ“ <strong>How are scores calculated?</strong> (click to expand)</summary>

<br>

## ğŸ“– Understanding This Leaderboard

This section explains how we measure and compare AI models.

> ğŸ’¡ **Don't worry if you're new to AI metrics** â€” we'll break it down step by step.

<br>

---

## ğŸ¯ The Main Metric: `AUROC`

### Area Under ROC Curve (AUROC)

**In simple terms:**

> Measures how well the model can tell apart different categories (e.g., healthy vs. diseased)

<br>

**How it works:**

Think of it like this: if you randomly pick one positive case and one negative case, AUROC tells you the probability that the model correctly identifies which is which. A score of 0.5 means the model is just guessing randomly (like flipping a coin), while 1.0 means it perfectly separates all cases.

<br>

**Score range:**

<div class="highlight"><pre><span></span><code>0.5 (random guessing) â†’ 1.0 (perfect separation)
</code></pre></div>

<br>

!!! example "Example"
    An AUROC of 0.85 means the model correctly ranks a positive case higher than a negative case 85% of the time.

<br>

---

## ğŸ§  How This Metric Fits This Task

Different tasks emphasize different aspects of performance.

**Here's how this metric should be interpreted for this benchmark:**

<br>

For **classification** tasks (e.g., disease vs. no disease), this metric helps you understand how reliably the model separates different outcome groups.

> ğŸ’¡ **Tip:** In addition to raw accuracy, look at metrics like **AUROC** and **F1 Score**, especially when classes are imbalanced (when positive cases are rare).

<br>

---

## ğŸ“Š Performance Tiers

### What Do the Scores Mean?

We group models into performance tiers to help you quickly understand how ready they are for different uses.

<br>

| Score Range | Rating | Interpretation | Suitable For |
|:---:|:---:|:---|:---|
| **â‰¥ 0.90** | â­ Excellent | Top-tier, consistently reliable | Clinical pilots (with oversight) |
| **0.80 â€“ 0.89** | âœ… Good | Strong performance, real promise | Validation studies |
| **0.70 â€“ 0.79** | ğŸ”¶ Fair | Moderate, has limitations | Research only |
| **< 0.70** | ğŸ“ˆ Developing | Needs improvement | Early research |

<br>

!!! warning "Important Context"
    These thresholds are **general guidelines**.

    The acceptable score depends on:

    - The specific clinical application
    - Risk level of the use case
    - Whether AI assists or replaces human judgment

    **Always consult domain experts** when evaluating fitness for a particular use case.

<br>

---

## ğŸ“ How We Determine Rankings

Models are ranked following these principles:

<br>

### 1ï¸âƒ£ Primary metric determines rank

The model with the highest score in the main metric ranks first.

> For metrics where **lower is better** (like error rates), the lowest score wins.

<br>

### 2ï¸âƒ£ Ties are broken by secondary metrics

If two models have identical primary scores, we look at other relevant metrics.

<br>

### 3ï¸âƒ£ Best run per model

If a model was evaluated multiple times (e.g., with different settings), only its **best result** appears on the leaderboard.

<br>

### 4ï¸âƒ£ Reproducibility required

All results must be reproducible. We record:

- Evaluation date
- Dataset used
- Configuration details

<br>

---

## ğŸ¥ Why This Matters for Healthcare AI

Healthcare AI has **higher stakes** than many other AI applications.

> A model that works 95% of the time might sound good, but that 5% could mean **missed diagnoses** or **incorrect treatments**.

<br>

**That's why we:**

âœ… Use **multiple metrics** to capture different aspects of performance

âœ… Test **robustness** to real-world data quality issues

âœ… Require **transparency** about evaluation conditions

âœ… Follow **international standards** for healthcare AI assessment

<br>

---

## ğŸŒ Standards Alignment

This benchmark follows the [ITU/WHO Focus Group on AI for Health (FG-AI4H)](https://www.itu.int/pub/T-FG-AI4H) framework.

<br>

This ensures our evaluations are:

| Quality | What it means |
|:--------|:--------------|
| **Rigorous** | Following established scientific methodology |
| **Comparable** | Using standardized metrics across models |
| **Trustworthy** | Aligned with WHO/ITU recommendations |

<br>

</details>

<hr />
<h4 id="cell-type-annotation">Cell Type Annotation</h4>
<p><em>Predicting cell types from single-cell RNA-seq data.</em></p>
<p><strong>2 models ranked by <code>AUROC</code>:</strong></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Rank</th>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Score</th>
<th style="text-align: center;">Level</th>
<th style="text-align: left;">Details</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ¥‡</td>
<td style="text-align: left;"><strong>Baseline (Random/Majority)</strong> ğŸ‘‘</td>
<td style="text-align: center;">0.0000</td>
<td style="text-align: center;">ğŸ“ˆ Developing</td>
<td style="text-align: left;">PBMC 3k (processed, , 2025-12-18</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ¥ˆ</td>
<td style="text-align: left;"><strong>geneformer</strong></td>
<td style="text-align: center;">0.0000</td>
<td style="text-align: center;">ğŸ“ˆ Developing</td>
<td style="text-align: left;">PBMC 3k (processed, , 2025-12-18</td>
</tr>
</tbody>
</table>
<div class="admonition tip">
<p class="admonition-title">Quick Comparison</p>
<p><strong>ğŸ¥‡ Baseline (Random/Majority)</strong> leads with AUROC = <strong>0.0000</strong></p>
<ul>
<li>Gap to ğŸ¥ˆ geneformer: +0.0000</li>
</ul>
</div>
<details>
<summary>ğŸ“ <strong>How are scores calculated?</strong> (click to expand)</summary>

<br>

## ğŸ“– Understanding This Leaderboard

This section explains how we measure and compare AI models.

> ğŸ’¡ **Don't worry if you're new to AI metrics** â€” we'll break it down step by step.

<br>

---

## ğŸ¯ The Main Metric: `AUROC`

### Area Under ROC Curve (AUROC)

**In simple terms:**

> Measures how well the model can tell apart different categories (e.g., healthy vs. diseased)

<br>

**How it works:**

Think of it like this: if you randomly pick one positive case and one negative case, AUROC tells you the probability that the model correctly identifies which is which. A score of 0.5 means the model is just guessing randomly (like flipping a coin), while 1.0 means it perfectly separates all cases.

<br>

**Score range:**

<div class="highlight"><pre><span></span><code>0.5 (random guessing) â†’ 1.0 (perfect separation)
</code></pre></div>

<br>

!!! example "Example"
    An AUROC of 0.85 means the model correctly ranks a positive case higher than a negative case 85% of the time.

<br>

---

## ğŸ§  How This Metric Fits This Task

Different tasks emphasize different aspects of performance.

**Here's how this metric should be interpreted for this benchmark:**

<br>

For **classification** tasks (e.g., disease vs. no disease), this metric helps you understand how reliably the model separates different outcome groups.

> ğŸ’¡ **Tip:** In addition to raw accuracy, look at metrics like **AUROC** and **F1 Score**, especially when classes are imbalanced (when positive cases are rare).

<br>

---

## ğŸ“Š Performance Tiers

### What Do the Scores Mean?

We group models into performance tiers to help you quickly understand how ready they are for different uses.

<br>

| Score Range | Rating | Interpretation | Suitable For |
|:---:|:---:|:---|:---|
| **â‰¥ 0.90** | â­ Excellent | Top-tier, consistently reliable | Clinical pilots (with oversight) |
| **0.80 â€“ 0.89** | âœ… Good | Strong performance, real promise | Validation studies |
| **0.70 â€“ 0.79** | ğŸ”¶ Fair | Moderate, has limitations | Research only |
| **< 0.70** | ğŸ“ˆ Developing | Needs improvement | Early research |

<br>

!!! warning "Important Context"
    These thresholds are **general guidelines**.

    The acceptable score depends on:

    - The specific clinical application
    - Risk level of the use case
    - Whether AI assists or replaces human judgment

    **Always consult domain experts** when evaluating fitness for a particular use case.

<br>

---

## ğŸ“ How We Determine Rankings

Models are ranked following these principles:

<br>

### 1ï¸âƒ£ Primary metric determines rank

The model with the highest score in the main metric ranks first.

> For metrics where **lower is better** (like error rates), the lowest score wins.

<br>

### 2ï¸âƒ£ Ties are broken by secondary metrics

If two models have identical primary scores, we look at other relevant metrics.

<br>

### 3ï¸âƒ£ Best run per model

If a model was evaluated multiple times (e.g., with different settings), only its **best result** appears on the leaderboard.

<br>

### 4ï¸âƒ£ Reproducibility required

All results must be reproducible. We record:

- Evaluation date
- Dataset used
- Configuration details

<br>

---

## ğŸ¥ Why This Matters for Healthcare AI

Healthcare AI has **higher stakes** than many other AI applications.

> A model that works 95% of the time might sound good, but that 5% could mean **missed diagnoses** or **incorrect treatments**.

<br>

**That's why we:**

âœ… Use **multiple metrics** to capture different aspects of performance

âœ… Test **robustness** to real-world data quality issues

âœ… Require **transparency** about evaluation conditions

âœ… Follow **international standards** for healthcare AI assessment

<br>

---

## ğŸŒ Standards Alignment

This benchmark follows the [ITU/WHO Focus Group on AI for Health (FG-AI4H)](https://www.itu.int/pub/T-FG-AI4H) framework.

<br>

This ensures our evaluations are:

| Quality | What it means |
|:--------|:--------------|
| **Rigorous** | Following established scientific methodology |
| **Comparable** | Using standardized metrics across models |
| **Trustworthy** | Aligned with WHO/ITU recommendations |

<br>

</details>

<hr />
<h4 id="dna-enhancer-classification">DNA Enhancer Classification</h4>
<p>*Benchmark for classifying DNA sequences as enhancers or non-enhancers.
Enhancers are distal regulatory elements that activate gene expression.
Accurate enhancer prediction is critical for understanding gene regulation
and identifying disease-associated variants.
*</p>
<div align="center">

<div class="highlight"><pre><span></span><code>                    ğŸ†                    

              ğŸ¥‡ HyenaDNA              
                 (0.788)                 
             â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—             
             â•‘               â•‘             
   ğŸ¥ˆ Caduceus   â•‘               â•‘   ğŸ¥‰  Evo 2     
      (0.745)      â•‘               â•‘      (0.745)      
  â•”â•â•â•â•â•â•â•â•â•â•â•â•               â•šâ•â•â•â•â•â•â•â•â•â•â•â•—  
  â•‘                                       â•‘  
â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•
</code></pre></div>

</div>

<p><strong>6 models ranked by <code>AUROC</code>:</strong></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Rank</th>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Score</th>
<th style="text-align: center;">Level</th>
<th style="text-align: left;">Details</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ¥‡</td>
<td style="text-align: left;"><strong>HyenaDNA</strong> ğŸ‘‘</td>
<td style="text-align: center;">0.7883</td>
<td style="text-align: center;">ğŸ”¶ Fair</td>
<td style="text-align: left;">DS-DNA-ENHANCER, 2025-12-18T21:03:03.285801</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ¥ˆ</td>
<td style="text-align: left;"><strong>Caduceus</strong></td>
<td style="text-align: center;">0.7453</td>
<td style="text-align: center;">ğŸ”¶ Fair</td>
<td style="text-align: left;">Human Enhancers (Coh, 2025-12-19T12:00:12.636691</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ¥‰</td>
<td style="text-align: left;"><strong>Evo 2</strong></td>
<td style="text-align: center;">0.7453</td>
<td style="text-align: center;">ğŸ”¶ Fair</td>
<td style="text-align: left;">Human Enhancers (Coh, 2025-12-19T12:00:13.160707</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ…</td>
<td style="text-align: left;">kmer_k6</td>
<td style="text-align: center;">0.7365</td>
<td style="text-align: center;">ğŸ”¶ Fair</td>
<td style="text-align: left;">Human Enhancers (Coh, 2025-12-18T18:44:08.075706</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ…</td>
<td style="text-align: left;">DNABERT-2</td>
<td style="text-align: center;">0.7365</td>
<td style="text-align: center;">ğŸ”¶ Fair</td>
<td style="text-align: left;">Human Enhancers (Coh, 2025-12-18T18:44:24.678525</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ–ï¸</td>
<td style="text-align: left;">HyenaDNA</td>
<td style="text-align: center;">0.7365</td>
<td style="text-align: center;">ğŸ”¶ Fair</td>
<td style="text-align: left;">Human Enhancers (Coh, 2025-12-18T18:44:17.006557</td>
</tr>
</tbody>
</table>
<div class="admonition tip">
<p class="admonition-title">Quick Comparison</p>
<p><strong>ğŸ¥‡ HyenaDNA</strong> leads with AUROC = <strong>0.7883</strong></p>
<ul>
<li>Gap to ğŸ¥ˆ Caduceus: +0.0430</li>
<li>Score spread (best to worst): 0.0518</li>
</ul>
</div>
<details>
<summary>ğŸ“ <strong>How are scores calculated?</strong> (click to expand)</summary>

<br>

## ğŸ“– Understanding This Leaderboard

This section explains how we measure and compare AI models.

> ğŸ’¡ **Don't worry if you're new to AI metrics** â€” we'll break it down step by step.

<br>

---

## ğŸ¯ The Main Metric: `AUROC`

### Area Under ROC Curve (AUROC)

**In simple terms:**

> Measures how well the model can tell apart different categories (e.g., healthy vs. diseased)

<br>

**How it works:**

Think of it like this: if you randomly pick one positive case and one negative case, AUROC tells you the probability that the model correctly identifies which is which. A score of 0.5 means the model is just guessing randomly (like flipping a coin), while 1.0 means it perfectly separates all cases.

<br>

**Score range:**

<div class="highlight"><pre><span></span><code>0.5 (random guessing) â†’ 1.0 (perfect separation)
</code></pre></div>

<br>

!!! example "Example"
    An AUROC of 0.85 means the model correctly ranks a positive case higher than a negative case 85% of the time.

<br>

---

## ğŸ§  How This Metric Fits This Task

Different tasks emphasize different aspects of performance.

**Here's how this metric should be interpreted for this benchmark:**

<br>

For **classification** tasks (e.g., disease vs. no disease), this metric helps you understand how reliably the model separates different outcome groups.

> ğŸ’¡ **Tip:** In addition to raw accuracy, look at metrics like **AUROC** and **F1 Score**, especially when classes are imbalanced (when positive cases are rare).

<br>

---

## ğŸ“Š Performance Tiers

### What Do the Scores Mean?

We group models into performance tiers to help you quickly understand how ready they are for different uses.

<br>

| Score Range | Rating | Interpretation | Suitable For |
|:---:|:---:|:---|:---|
| **â‰¥ 0.90** | â­ Excellent | Top-tier, consistently reliable | Clinical pilots (with oversight) |
| **0.80 â€“ 0.89** | âœ… Good | Strong performance, real promise | Validation studies |
| **0.70 â€“ 0.79** | ğŸ”¶ Fair | Moderate, has limitations | Research only |
| **< 0.70** | ğŸ“ˆ Developing | Needs improvement | Early research |

<br>

!!! warning "Important Context"
    These thresholds are **general guidelines**.

    The acceptable score depends on:

    - The specific clinical application
    - Risk level of the use case
    - Whether AI assists or replaces human judgment

    **Always consult domain experts** when evaluating fitness for a particular use case.

<br>

---

## ğŸ“ How We Determine Rankings

Models are ranked following these principles:

<br>

### 1ï¸âƒ£ Primary metric determines rank

The model with the highest score in the main metric ranks first.

> For metrics where **lower is better** (like error rates), the lowest score wins.

<br>

### 2ï¸âƒ£ Ties are broken by secondary metrics

If two models have identical primary scores, we look at other relevant metrics.

<br>

### 3ï¸âƒ£ Best run per model

If a model was evaluated multiple times (e.g., with different settings), only its **best result** appears on the leaderboard.

<br>

### 4ï¸âƒ£ Reproducibility required

All results must be reproducible. We record:

- Evaluation date
- Dataset used
- Configuration details

<br>

---

## ğŸ¥ Why This Matters for Healthcare AI

Healthcare AI has **higher stakes** than many other AI applications.

> A model that works 95% of the time might sound good, but that 5% could mean **missed diagnoses** or **incorrect treatments**.

<br>

**That's why we:**

âœ… Use **multiple metrics** to capture different aspects of performance

âœ… Test **robustness** to real-world data quality issues

âœ… Require **transparency** about evaluation conditions

âœ… Follow **international standards** for healthcare AI assessment

<br>

---

## ğŸŒ Standards Alignment

This benchmark follows the [ITU/WHO Focus Group on AI for Health (FG-AI4H)](https://www.itu.int/pub/T-FG-AI4H) framework.

<br>

This ensures our evaluations are:

| Quality | What it means |
|:--------|:--------------|
| **Rigorous** | Following established scientific methodology |
| **Comparable** | Using standardized metrics across models |
| **Trustworthy** | Aligned with WHO/ITU recommendations |

<br>

</details>

<hr />
<h3 id="generation">âœï¸ Generation</h3>
<h4 id="clinical-report-generation-quality">Clinical Report Generation Quality</h4>
<div class="admonition warning">
<p class="admonition-title">No submissions yet</p>
<p>Be the first! See <a href="../contributing/submission_guide/">Submission Guide</a></p>
</div>
<h2 id="brain-imaging-mrifmri">ğŸ§  Brain Imaging (MRI/fMRI)</h2>
<h3 id="classification_1">ğŸ¯ Classification</h3>
<h4 id="toy-classification-benchmark">Toy Classification Benchmark</h4>
<p><em>A toy benchmark for testing the pipeline.</em></p>
<p><strong>2 models ranked by <code>AUROC</code>:</strong></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Rank</th>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Score</th>
<th style="text-align: center;">Level</th>
<th style="text-align: left;">Details</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ¥‡</td>
<td style="text-align: left;"><strong>Baseline (Random/Majority)</strong> ğŸ‘‘</td>
<td style="text-align: center;">0.5597</td>
<td style="text-align: center;">ğŸ“ˆ Developing</td>
<td style="text-align: left;">Toy fMRI Classificat, 2025-11-27</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ¥ˆ</td>
<td style="text-align: left;"><strong>BrainLM</strong></td>
<td style="text-align: center;">0.5193</td>
<td style="text-align: center;">ğŸ“ˆ Developing</td>
<td style="text-align: left;">Toy fMRI Classificat, 2025-11-27</td>
</tr>
</tbody>
</table>
<div class="admonition tip">
<p class="admonition-title">Quick Comparison</p>
<p><strong>ğŸ¥‡ Baseline (Random/Majority)</strong> leads with AUROC = <strong>0.5597</strong></p>
<ul>
<li>Gap to ğŸ¥ˆ BrainLM: +0.0404</li>
</ul>
</div>
<details>
<summary>ğŸ“ <strong>How are scores calculated?</strong> (click to expand)</summary>

<br>

## ğŸ“– Understanding This Leaderboard

This section explains how we measure and compare AI models.

> ğŸ’¡ **Don't worry if you're new to AI metrics** â€” we'll break it down step by step.

<br>

---

## ğŸ¯ The Main Metric: `AUROC`

### Area Under ROC Curve (AUROC)

**In simple terms:**

> Measures how well the model can tell apart different categories (e.g., healthy vs. diseased)

<br>

**How it works:**

Think of it like this: if you randomly pick one positive case and one negative case, AUROC tells you the probability that the model correctly identifies which is which. A score of 0.5 means the model is just guessing randomly (like flipping a coin), while 1.0 means it perfectly separates all cases.

<br>

**Score range:**

<div class="highlight"><pre><span></span><code>0.5 (random guessing) â†’ 1.0 (perfect separation)
</code></pre></div>

<br>

!!! example "Example"
    An AUROC of 0.85 means the model correctly ranks a positive case higher than a negative case 85% of the time.

<br>

---

## ğŸ§  How This Metric Fits This Task

Different tasks emphasize different aspects of performance.

**Here's how this metric should be interpreted for this benchmark:**

<br>

For **classification** tasks (e.g., disease vs. no disease), this metric helps you understand how reliably the model separates different outcome groups.

> ğŸ’¡ **Tip:** In addition to raw accuracy, look at metrics like **AUROC** and **F1 Score**, especially when classes are imbalanced (when positive cases are rare).

<br>

---

## ğŸ“Š Performance Tiers

### What Do the Scores Mean?

We group models into performance tiers to help you quickly understand how ready they are for different uses.

<br>

| Score Range | Rating | Interpretation | Suitable For |
|:---:|:---:|:---|:---|
| **â‰¥ 0.90** | â­ Excellent | Top-tier, consistently reliable | Clinical pilots (with oversight) |
| **0.80 â€“ 0.89** | âœ… Good | Strong performance, real promise | Validation studies |
| **0.70 â€“ 0.79** | ğŸ”¶ Fair | Moderate, has limitations | Research only |
| **< 0.70** | ğŸ“ˆ Developing | Needs improvement | Early research |

<br>

!!! warning "Important Context"
    These thresholds are **general guidelines**.

    The acceptable score depends on:

    - The specific clinical application
    - Risk level of the use case
    - Whether AI assists or replaces human judgment

    **Always consult domain experts** when evaluating fitness for a particular use case.

<br>

---

## ğŸ“ How We Determine Rankings

Models are ranked following these principles:

<br>

### 1ï¸âƒ£ Primary metric determines rank

The model with the highest score in the main metric ranks first.

> For metrics where **lower is better** (like error rates), the lowest score wins.

<br>

### 2ï¸âƒ£ Ties are broken by secondary metrics

If two models have identical primary scores, we look at other relevant metrics.

<br>

### 3ï¸âƒ£ Best run per model

If a model was evaluated multiple times (e.g., with different settings), only its **best result** appears on the leaderboard.

<br>

### 4ï¸âƒ£ Reproducibility required

All results must be reproducible. We record:

- Evaluation date
- Dataset used
- Configuration details

<br>

---

## ğŸ¥ Why This Matters for Healthcare AI

Healthcare AI has **higher stakes** than many other AI applications.

> A model that works 95% of the time might sound good, but that 5% could mean **missed diagnoses** or **incorrect treatments**.

<br>

**That's why we:**

âœ… Use **multiple metrics** to capture different aspects of performance

âœ… Test **robustness** to real-world data quality issues

âœ… Require **transparency** about evaluation conditions

âœ… Follow **international standards** for healthcare AI assessment

<br>

---

## ğŸŒ Standards Alignment

This benchmark follows the [ITU/WHO Focus Group on AI for Health (FG-AI4H)](https://www.itu.int/pub/T-FG-AI4H) framework.

<br>

This ensures our evaluations are:

| Quality | What it means |
|:--------|:--------------|
| **Rigorous** | Following established scientific methodology |
| **Comparable** | Using standardized metrics across models |
| **Trustworthy** | Aligned with WHO/ITU recommendations |

<br>

</details>

<hr />
<h3 id="classificationreconstruction">ğŸ“‹ Classification/Reconstruction</h3>
<h4 id="fmri-foundation-model-benchmark-granular">fMRI Foundation Model Benchmark (Granular)</h4>
<p><strong>2 models ranked by <code>AUROC</code>:</strong></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Rank</th>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Score</th>
<th style="text-align: center;">Level</th>
<th style="text-align: left;">Details</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ¥‡</td>
<td style="text-align: left;"><strong>BrainLM</strong> ğŸ‘‘</td>
<td style="text-align: center;">1.0000</td>
<td style="text-align: center;">â­ Excellent</td>
<td style="text-align: left;">DS-TOY-FMRI, 2025-12-19T12:00:49.423857</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ¥ˆ</td>
<td style="text-align: left;"><strong>Brain-JEPA</strong></td>
<td style="text-align: center;">1.0000</td>
<td style="text-align: center;">â­ Excellent</td>
<td style="text-align: left;">DS-TOY-FMRI, 2025-12-19T12:00:49.427678</td>
</tr>
</tbody>
</table>
<div class="admonition tip">
<p class="admonition-title">Quick Comparison</p>
<p><strong>ğŸ¥‡ BrainLM</strong> leads with AUROC = <strong>1.0000</strong></p>
<ul>
<li>Gap to ğŸ¥ˆ Brain-JEPA: +0.0000</li>
</ul>
</div>
<details>
<summary>ğŸ“ <strong>How are scores calculated?</strong> (click to expand)</summary>

<br>

## ğŸ“– Understanding This Leaderboard

This section explains how we measure and compare AI models.

> ğŸ’¡ **Don't worry if you're new to AI metrics** â€” we'll break it down step by step.

<br>

---

## ğŸ¯ The Main Metric: `AUROC`

### Area Under ROC Curve (AUROC)

**In simple terms:**

> Measures how well the model can tell apart different categories (e.g., healthy vs. diseased)

<br>

**How it works:**

Think of it like this: if you randomly pick one positive case and one negative case, AUROC tells you the probability that the model correctly identifies which is which. A score of 0.5 means the model is just guessing randomly (like flipping a coin), while 1.0 means it perfectly separates all cases.

<br>

**Score range:**

<div class="highlight"><pre><span></span><code>0.5 (random guessing) â†’ 1.0 (perfect separation)
</code></pre></div>

<br>

!!! example "Example"
    An AUROC of 0.85 means the model correctly ranks a positive case higher than a negative case 85% of the time.

<br>

---

## ğŸ§  How This Metric Fits This Task

Different tasks emphasize different aspects of performance.

**Here's how this metric should be interpreted for this benchmark:**

<br>

For **classification** tasks (e.g., disease vs. no disease), this metric helps you understand how reliably the model separates different outcome groups.

> ğŸ’¡ **Tip:** In addition to raw accuracy, look at metrics like **AUROC** and **F1 Score**, especially when classes are imbalanced (when positive cases are rare).

<br>

---

## ğŸ“Š Performance Tiers

### What Do the Scores Mean?

We group models into performance tiers to help you quickly understand how ready they are for different uses.

<br>

| Score Range | Rating | Interpretation | Suitable For |
|:---:|:---:|:---|:---|
| **â‰¥ 0.90** | â­ Excellent | Top-tier, consistently reliable | Clinical pilots (with oversight) |
| **0.80 â€“ 0.89** | âœ… Good | Strong performance, real promise | Validation studies |
| **0.70 â€“ 0.79** | ğŸ”¶ Fair | Moderate, has limitations | Research only |
| **< 0.70** | ğŸ“ˆ Developing | Needs improvement | Early research |

<br>

!!! warning "Important Context"
    These thresholds are **general guidelines**.

    The acceptable score depends on:

    - The specific clinical application
    - Risk level of the use case
    - Whether AI assists or replaces human judgment

    **Always consult domain experts** when evaluating fitness for a particular use case.

<br>

---

## ğŸ“ How We Determine Rankings

Models are ranked following these principles:

<br>

### 1ï¸âƒ£ Primary metric determines rank

The model with the highest score in the main metric ranks first.

> For metrics where **lower is better** (like error rates), the lowest score wins.

<br>

### 2ï¸âƒ£ Ties are broken by secondary metrics

If two models have identical primary scores, we look at other relevant metrics.

<br>

### 3ï¸âƒ£ Best run per model

If a model was evaluated multiple times (e.g., with different settings), only its **best result** appears on the leaderboard.

<br>

### 4ï¸âƒ£ Reproducibility required

All results must be reproducible. We record:

- Evaluation date
- Dataset used
- Configuration details

<br>

---

## ğŸ¥ Why This Matters for Healthcare AI

Healthcare AI has **higher stakes** than many other AI applications.

> A model that works 95% of the time might sound good, but that 5% could mean **missed diagnoses** or **incorrect treatments**.

<br>

**That's why we:**

âœ… Use **multiple metrics** to capture different aspects of performance

âœ… Test **robustness** to real-world data quality issues

âœ… Require **transparency** about evaluation conditions

âœ… Follow **international standards** for healthcare AI assessment

<br>

---

## ğŸŒ Standards Alignment

This benchmark follows the [ITU/WHO Focus Group on AI for Health (FG-AI4H)](https://www.itu.int/pub/T-FG-AI4H) framework.

<br>

This ensures our evaluations are:

| Quality | What it means |
|:--------|:--------------|
| **Rigorous** | Following established scientific methodology |
| **Comparable** | Using standardized metrics across models |
| **Trustworthy** | Aligned with WHO/ITU recommendations |

<br>

</details>

<hr />
<h3 id="reconstruction">ğŸ”„ Reconstruction</h3>
<h4 id="brain-time-series-modeling">Brain Time-Series Modeling</h4>
<p><em>Evaluating ability to reconstruct masked fMRI voxel time-series.</em></p>
<div class="admonition warning">
<p class="admonition-title">No submissions yet</p>
<p>Be the first! See <a href="../contributing/submission_guide/">Submission Guide</a></p>
</div>
<h2 id="other-benchmarks">ğŸ“‹ Other Benchmarks</h2>
<h3 id="foundation-model-robustness-evaluation">Foundation Model Robustness Evaluation</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">Rank</th>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Score</th>
<th style="text-align: center;">Level</th>
<th style="text-align: left;">Details</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ¥‡</td>
<td style="text-align: left;"><strong>geneformer</strong> ğŸ‘‘</td>
<td style="text-align: center;">0.9995</td>
<td style="text-align: center;">â­ Excellent</td>
<td style="text-align: left;">neuro/robustness, 2025-11-27</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ¥ˆ</td>
<td style="text-align: left;"><strong>BrainLM</strong></td>
<td style="text-align: center;">0.9451</td>
<td style="text-align: center;">â­ Excellent</td>
<td style="text-align: left;">DS-TOY-FMRI-ROBUSTNE, 2025-12-19T12:01:52.781177</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ¥‰</td>
<td style="text-align: left;"><strong>Brain-JEPA</strong></td>
<td style="text-align: center;">0.9377</td>
<td style="text-align: center;">â­ Excellent</td>
<td style="text-align: left;">DS-TOY-FMRI-ROBUSTNE, 2025-12-19T12:01:52.789369</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ…</td>
<td style="text-align: left;">SWIFT</td>
<td style="text-align: center;">0.9234</td>
<td style="text-align: center;">â­ Excellent</td>
<td style="text-align: left;">DS-TOY-FMRI-ROBUSTNE, 2025-12-18T21:25:36.388271</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ…</td>
<td style="text-align: left;">Baseline (Random/Majority)</td>
<td style="text-align: center;">0.7810</td>
<td style="text-align: center;">ğŸ”¶ Fair</td>
<td style="text-align: left;">neuro/robustness, 2025-11-27</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="add-your-model">ğŸš€ Add Your Model</h2>
<p>Want your model on this leaderboard?</p>
<ol>
<li><strong>Download</strong> the benchmark toolkit</li>
<li><strong>Run locally</strong> on your model (your code stays private!)</li>
<li><strong>Submit results</strong> via <a href="https://github.com/allison-eunse/ai4h-inspired-fm-benchmark-hub/issues/new?template=benchmark_submission.md">GitHub Issue</a></li>
</ol>
<p><a class="md-button md-button--primary" href="../">ğŸ“¥ Get Started</a>
<a class="md-button" href="../contributing/submission_guide/">ğŸ“– Submission Guide</a></p>
<hr />
<p><em>Aligned with <a href="https://www.itu.int/pub/T-FG-AI4H">ITU/WHO FG-AI4H</a> standards for healthcare AI evaluation.</em></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.top", "navigation.tracking", "navigation.instant", "navigation.expand", "toc.integrate", "content.code.copy", "search.suggest", "search.highlight"], "search": "../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>