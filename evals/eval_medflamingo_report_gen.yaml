# Second model for Report Generation - to demonstrate rankings
eval_id: eval_medflamingo_report_gen_001
benchmark_id: BM-REPORT-GEN

model_ids:
  candidate: medflamingo

dataset_id: mimic_cxr_reports

run_metadata:
  date: "2024-01-18"
  runner: "fmbench"
  hardware: "8x NVIDIA A100"

metrics:
  report_quality_score: 0.7800
  clinical_accuracy: 0.8200
  finding_recall: 0.7900
  finding_precision: 0.8500
  hallucination_rate: 0.0900
  omission_rate: 0.1200
  bertscore: 0.8200
  bleu: 32.5
  meteor: 0.4800
  rouge_l: 0.5500
  flesch_kincaid: 11.5
  structure_score: 0.8200
  harmful_content: 0.0020
  uncertainty_calibration: 0.7500

  stratified:
    report_type:
      chest_xray:
        clinical_accuracy: 0.8500
        finding_recall: 0.8100
        bertscore: 0.8300
        N: 2000
      brain_mri:
        clinical_accuracy: 0.8000
        finding_recall: 0.7600
        bertscore: 0.8000
        N: 600
      ct_abdomen:
        clinical_accuracy: 0.7800
        finding_recall: 0.7400
        bertscore: 0.7900
        N: 800

status: Completed

